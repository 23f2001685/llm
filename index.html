<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Agent POC</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        .chat-container { max-height: 500px; overflow-y: auto; }
        .message { margin-bottom: 15px; }
        .user-message { background-color: #e3f2fd; }
        .assistant-message { background-color: #f5f5f5; }
        .tool-result { background-color: #fff3cd; font-family: monospace; font-size: 0.9em; }
    </style>
</head>
<body>
    <div class="container mt-4">
        <h1 class="text-center mb-4">ü§ñ LLM Agent POC</h1>
        
        <!-- Error Alerts -->
        <div id="alertContainer"></div>
        
        <!-- Provider & Model Selection -->
        <div class="row mb-3">
            <div class="col-md-6">
                <label for="providerSelect" class="form-label">Provider:</label>
                <select id="providerSelect" class="form-select">
                    <option value="nvidia">NVIDIA API (Best Performance)</option>
                    <option value="aipipe">AI Pipe API</option>
                    <option value="aiproxy">AI Proxy API</option>
                </select>
            </div>
            <div class="col-md-6">
                <label for="modelSelect" class="form-label">NVIDIA Model:</label>
                <select id="modelSelect" class="form-select">
                    <option value="deepseek-r1">DeepSeek R1 (Recommended)</option>
                    <option value="llama-4-maverick">Llama 4 Maverick</option>
                    <option value="llama-4-scout">Llama 4 Scout</option>
                    <option value="llama-3.3">Llama 3.3 70B</option>
                    <option value="qwen-coder">Qwen 2.5 Coder</option>
                </select>
            </div>
        </div>
        
        <!-- Chat Window -->
        <div class="card mb-3">
            <div class="card-header">
                <h5>üí¨ Conversation</h5>
            </div>
            <div class="card-body chat-container" id="chatContainer">
                <div class="message assistant-message">
                    <strong>Assistant:</strong> üöÄ Welcome to the Enhanced LLM Agent with NVIDIA Integration!
                    <ul>
                        <li>üîç <strong>Google Search</strong> - Find real-time information</li>
                        <li>üíª <strong>JavaScript Execution</strong> - Run code safely in sandbox</li>
                        <li>üß† <strong>AI Pipe Processing</strong> - Advanced AI workflows</li>
                        <li>üöÄ <strong>NVIDIA Models</strong> - DeepSeek R1, Llama 4, Qwen Coder</li>
                    </ul>
                    Choose your preferred model and ask me anything! I can search, calculate, code, and process data.
                </div>
            </div>
        </div>
        
        <!-- Input -->
        <div class="input-group">
            <input type="text" id="userInput" class="form-control" 
                   placeholder="Ask me anything... I can search, code, or process data!" 
                   onkeypress="if(event.key==='Enter') sendMessage()">
            <button class="btn btn-primary" onclick="sendMessage()">Send</button>
        </div>
        
        <!-- Enhanced Tool Status -->
        <div class="mt-3">
            <small class="text-muted">
                ÔøΩ <strong>NVIDIA Enhanced:</strong> DeepSeek R1 | Llama 4 | Qwen Coder<br>
                üîß <strong>Tools:</strong> Google Search | JavaScript Execution | AI Pipe Processing<br>
                ‚ö° <strong>APIs:</strong> NVIDIA | AI Pipe | AI Proxy
            </small>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="agent_minimal.js"></script>
</body>
</html>
